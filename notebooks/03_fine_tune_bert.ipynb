{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbc02b9a",
   "metadata": {},
   "source": [
    "# AI-Generated Text Detection - Fine-tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run preprocessing script to ensure dataset is ready\n",
    "!python ../scripts/data_preprocessing.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cef5d2",
   "metadata": {},
   "source": [
    "## Train BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bb5c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fine-tune BERT on the dataset\n",
    "!python ../scripts/train_bert.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec34c3",
   "metadata": {},
   "source": [
    "## Load and Evaluate BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01faeb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_dir = '../models/bert_model'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
    "model = BertForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Example evaluation on a sample text\n",
    "sample_text = \"This is an example sentence to check if the model thinks it is AI or human.\"\n",
    "inputs = tokenizer(sample_text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "print(f\"Sample text prediction: {'AI-generated' if prediction == 1 else 'Human-written'}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
